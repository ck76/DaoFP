\documentclass[DaoFP]{subfiles}
\begin{document}
 \setcounter{chapter}{16}

 \chapter{Ends and Coends（极限与余极限）}

 \section{Profunctors（泛函）}

 在范畴论的高度抽象中，我们会遇到一些模式，这些模式离其起源如此遥远，以至于我们难以将其具象化。更为抽象的模式通常与其具体实例的相似度更低，这使得我们理解起来更加困难。

 从$a$到$b$的箭头（arrow）相对容易理解。我们对它有一个非常熟悉的模型：一个函数，它消耗$a$的元素并生成$b$的元素。态射集（hom-set）是一组这样的箭头的集合。

 函子（functor）是范畴之间的箭头。它消耗来自一个范畴的对象和箭头，并生成另一个范畴中的对象和箭头。我们可以将其视为一种使用源范畴提供的材料来构建这些对象（和箭头）的配方。尤其是，我们通常将自函子（endofunctor）视为构建材料的容器。

 泛函（profunctor）将一对对象$\langle a, b \rangle$映射到一个集合$P\langle a, b \rangle$，并将一对箭头
 \[ \langle f \colon s \to a, g \colon b \to t \rangle \]
 映射到一个函数：
 \[ P\langle f, g \rangle \colon P\langle a, b \rangle \to P\langle s, t \rangle \]

 泛函是结合了许多其他抽象元素的抽象。因为它是一个从$ \mathcal{C}^{op} \times  \mathcal{C}$到$\mathbf{Set}$的函子，我们可以将其视为从一对对象中构造一个集合，并从一对箭头（其中一个箭头的方向相反）中构造一个函数。然而，这并不有助于我们进行想象。

 幸运的是，我们有一个关于泛函的良好模型：同态函子（hom-functor）。在变动对象时，两者之间的箭头集表现得像一个泛函。并且明显的是，改变源对象和目标对象的同态集（hom-set）之间存在区别。

 因此，我们可以将任意泛函视为同态函子的泛化。泛函在已有的同态集基础上，为对象之间提供了额外的桥梁。

 然而，泛函$ \mathcal{C}(a, b)$的元素与集合$P\langle a, b \rangle$的元素之间有一个很大的区别。前者的元素是箭头，而箭头可以组合（compose）。对于泛函如何组合，并没有一目了然的方法。

 当然，可以认为泛函通过提升箭头（lifting of arrows）来泛化组合——不过不是在泛函之间，而是在同态集与泛函之间。例如，我们可以用箭头$f \colon s \to a$来“预组合”$P \langle a, b \rangle$，以得到$P \langle s, b \rangle$：
 \[ P\langle f, id_b \rangle \colon P \langle a, b \rangle \to P \langle s, b \rangle \]
 类似地，我们可以用$g \colon b \to t$“后组合”它：
 \[ P \langle id_a, g \rangle \colon P \langle a, b \rangle \to P \langle a, t \rangle \]
 这种异质的组合方式，接受由一个箭头和一个泛函元素组成的可组合对，并生成一个泛函的元素。

 泛函可以通过提升一对箭头在两侧进行扩展：

 \[
  \begin{tikzcd}
   & s
   \arrow[r, bend left, dashed, blue, "f"]
   & a
   \arrow[r, bend right, "P"]
   & b
   \arrow[r, bend left, dashed, blue, "g"]
   &  t
  \end{tikzcd}
 \]

 \subsection{Collages（拼接）}

 没有理由将泛函限制在单一范畴上。我们可以轻松定义一个在两个范畴之间的泛函，例如$ P \colon \mathcal{C}^{op} \times  \mathcal{D} \to \mathbf{Set}$。这样的泛函可以通过生成从$\mathcal{C}$中的对象到$\mathcal{D}$中的对象的同态集（hom-set）来将两个范畴连接在一起。

 两个范畴$\mathcal{C}$和$\mathcal{D}$的拼接（collage）是一个范畴，其对象是来自两个范畴的对象（不相交的并集）。对于两个对象$x$和$y$之间的同态集，要么是$\mathcal{C}$中的同态集（如果两个对象都在$\mathcal{C}$中）；要么是$\mathcal{D}$中的同态集（如果两个对象都在$\mathcal{D}$中）；要么是集合$P \langle x, y\rangle$（如果$x$在$\mathcal{C}$中，$y$在$\mathcal{D}$中）。否则，同态集是空的。

 态射的组合是通常的组合方式，除非其中一个态射是$P \langle x, y \rangle$的元素。这种情况下，我们需要提升我们尝试进行前组合或后组合的态射。

 很容易看出，拼接确实是一个范畴。新的态射跨越了拼接的两边，有时被称为异态射（heteromorphisms）。它们只能从$\mathcal{C}$到$\mathcal{D}$，而不能反向进行。

 从这个角度看，一个从$ \mathcal{C}^{op} \times  \mathcal{C}$到$\mathbf{Set}$的泛函应该真正被称为一个\emph{内}泛函（endo-profunctor）。它定义了$\mathcal{C}$与其自身的拼接。

 \begin{exercise}
  证明从两个范畴的拼接到一个有两个对象和一个箭头（以及两个恒等箭头）的“步行箭头”范畴（walking arrow category）之间存在一个函子。
 \end{exercise}

 \begin{exercise}
  证明，如果从$\mathcal{C}$到步行箭头范畴存在一个函子，那么$\mathcal{C}$可以分解成两个范畴的拼接。
 \end{exercise}

 \subsection{Profunctors as relations（作为关系的泛函）}

 在微观层面上，泛函看起来像一个同态函子，并且集合$P \langle a, b \rangle$的元素看起来像个别箭头。但是，当我们放大观察时，可以将泛函视为对象之间的关系。这些关系不是普通的关系；它们是\emph{证明相关关系}（proof-relevant relations）。

 为了更好地理解这一概念，让我们考虑一个普通的函子$F \colon \mathcal{C} \to \mathbf{Set}$（换句话说，一个余预层（co-presheaf））。可以将其解释为，它定义了$\mathcal{C}$对象的一个\emph{证明相关子集}（proof-relevant subset），即映射到非空集合的那些对象。$F a$中的每个元素都被视为$a$是此子集成员的证明。另一方面，如果$F a$是一个空集合，则$a$不是该子集的成员。

 我们可以对泛函应用相同的解释。如果集合$P \langle a, b \rangle$为空，我们说$b$与$a$不相关。如果它非空，我们说该集合中的每个元素代表了$b$与$a$相关的一个证明。然后，我们可以将泛函视为一种证明相关的关系。

 请注意，我们对这种关系没有做任何假设。它不必是自反的，因为$P \langle a, a \rangle$可能为空（实际上，$P \langle a, a \rangle$仅对内泛函有意义）。它也不必是对称的。

 由于同态函子是（内）泛函的一个例子，这种解释使我们可以从新的角度看待同态函子：作为范畴中对象之间的一种内建的证明相关关系。如果两个对象之间有箭头，它们是相关的。请注意，这种关系是自反的，因为$\mathcal{C}(a, a)$从不为空：至少它包含恒等态射。

 此外，正如我们之前所见，同态函子与泛函相互作用。如果$a$通过$P$与$b$相关，并且同态集$\mathcal{C}(s, a)$和$\mathcal{D}(b, t)$是非空的，那么$s$与$t$通过$P$自动相关。因此，泛函是与它们所操作的范畴结构兼容的证明相关关系。

 我们知道如何将同态函子与泛函组合在一起，但我们如何组合两个泛函呢？我们可以从关系的组合中得到线索。

 假设你想为手机充电，但你没有充电器。要将你连接到充电器，你只需有一个拥有充电器的朋友。任何朋友都可以。你将拥有朋友的关系与拥有充电器的关系组合在一起，以获得可以为手机充电的关系。你能够为手机充电的证明是一对证明：一个是友情的证明，一个是拥有充电器的证明。

 一般而言，我们说，如果存在一个中间对象与两者都相关，那么两个对象通过组合关系相关。

 \subsection{Profunctor composition in Haskell（Haskell中的泛函组合）}

 关系的组合可以翻译为Haskell中的泛函组合。首先回顾泛函的定义：
 \begin{haskell}
  class Profunctor p where
  dimap :: (s -> a) -> (b -> t) -> (p a b -> p s t)
 \end{haskell}

 理解泛函组合的关键在于它需要中间对象的\emph{存在}。对于对象$b$通过组合$P \diamond Q$与对象$a$相关，必须存在一个对象$x$来弥合这个差距：
 \[
  \begin{tikzcd}
   & a
   \arrow[r, bend left, blue, "Q"]
   & x
   \arrow[r, bend left, red, "P"]
   & b
  \end{tikzcd}
 \]

 这可以在Haskell中使用存在类型进行编码。给定两个泛函\hask{p}和\hask{q}，它们的组合是一个新的泛函\hask{Procompose p q}：
 \begin{haskell}
  data Procompose p q a b where
  Procompose ::  q a x -> p x b -> Procompose p q a b
 \end{haskell}
 我们使用\hask{GADT}来表达对象\hask{x}的存在性。数据构造函数的两个参数可以看作是一对证明：一个证明\hask{x}与\hask{a}相关，另一个证明\hask{b}与\hask{x}相关。然后，这对证明构成了\hask{b}与\hask{a}相关的证明。

 存在类型可以被视为和类型的推广。我们正在对所有可能的类型\hask{x}进行求和。就像有限求和可以通过注入其中一个备选项来构造（想想\hask{Either}的两个构造函数），存在类型可以通过为\hask{x}选择一个特定类型并将其注入\hask{Procompose}的定义中来构造。

 就像从和类型映射出需要一对函数，每个备选项一个；从存在类型映射出需要一个函数族，每个类型一个。比如，从\hask{Procompose}映射出的函数由一个多态函数定义：
 \begin{haskell}
  mapOut :: Procompose p q a b -> (forall x. q a x -> p x b -> c) -> c
  mapOut (Procompose qax pxb) f = (f qax pxb)
 \end{haskell}

 泛函的组合本身也是一个泛函，如以下实例所示：
 \begin{haskell}
  instance (Profunctor p, Profunctor q) => Profunctor (Procompose p q)
  where
  dimap l r (Procompose qax pxb) =
  Procompose (dimap l id qax) (dimap id r pxb)
 \end{haskell}
 这只是说你可以通过将第一个泛函扩展到左边，将第二个泛函扩展到右边来扩展组合泛函。

 在Haskell中这个泛函组合定义之所以能正常工作，是由于参数多态性。语言通过类型限制了泛函，使其能够正常工作。然而，一般来说，如果仅对中间对象进行简单求和，会导致过度计数，因此在范畴论中我们必须对此进行补偿。

 \section{Coends（余极限）}

 在泛函组合的简单定义中，过度计数发生在两个候选中间对象之间通过一个态射连接时：
 \[
  \begin{tikzcd}
   & a
   \arrow[r, bend left, blue, "Q"]
   &x
   \arrow[r, dashed, "f"]
   & y
   \arrow[r, bend left, red, "P"]
   & b
  \end{tikzcd}
 \]
 我们可以在右边扩展$Q$，通过提升$Q \langle id, f \rangle$，并使用$y$作为中间对象；或者我们可以在左边扩展$P$，通过提升$P \langle f, id \rangle$，并使用$x$作为中介。

 为了避免双重计数，我们必须在应用于泛函时调整我们的和类型定义。得到的构造被称为余极限（coend）。

 首先，让我们重新表述问题。我们试图对所有对象$x$在乘积上求和：
 \[ P \langle a, x \rangle \times Q \langle x, b \rangle \]
 双重计数发生是因为我们可以在两个泛函之间打开一个间隙，只要有一个态射可以填充其中。因此，我们真正关注的是一个更通用的乘积：
 \[ P \langle a, x \rangle \times Q \langle y, b \rangle \]
 重要的是，如果我们固定端点$a$和$b$，这个乘积是$\langle y, x \rangle$中的一个泛函。这可以通过一些排列（同构）轻松看出：
 \[ Q \langle y, b \rangle \times P \langle a, x \rangle \]
 我们感兴趣的是这个泛函的对角部分的和，也就是说，当$x$等于$y$时。

 因此，让我们看看如何定义一个泛函$P$的对角项的和。实际上，这种构造适用于任何函子$P \colon \cat C^{op} \times \cat C \to D$，而不仅仅是$\Set$值的泛函。

 对角项的和由注入定义；在这种情况下，每个对象$\cat C$有一个注入。这里我们只展示其中的两个，虚线代表所有其他的注入：
 \[
  \begin{tikzcd}
   P \langle y, y \rangle
   \arrow[dr, "i_y"']
   \arrow[rr, dash, dashed]
   &&P \langle x, x \rangle
   \arrow[dl, "i_x"]
   \\
   & d
  \end{tikzcd}
 \]

 如果我们在定义一个和，我们会使其成为一个带有这些注入的泛函对象。但由于我们处理的是两个变量的函子，我们希望识别那些通过“扩展”一些公共祖先（这里是$P \langle y, x \rangle$）而相关的注入。我们希望下图在存在连接态射$f \colon x \to y$时交换：

 \[
  \begin{tikzcd}
   &P \langle y, x \rangle
   \arrow[ld, "{P \langle id, f \rangle}"']
   \arrow[rd, "{P \langle f, id \rangle}"]
   \\
   P \langle y, y \rangle
   \arrow[dr, "i_y"']
   &&P \langle x, x \rangle
   \arrow[dl, "i_x"]
   \\
   &d
  \end{tikzcd}
 \]
 这个图被称为\emph{余楔形图}（co-wedge），其交换条件称为余楔条件。对于每个$f \colon x \to y$，我们要求：
 \[ i_x \circ P \langle f, id_y \rangle = i_y \circ P \langle id_x, f \rangle \]
 \emph{通用}余楔被称为余极限（coend）。

 由于余极限将和推广到可能的无限域，我们用积分符号表示它，上方标出“积分变量”：
 \[ \int^{x\colon \mathcal{C}} P \langle x, x \rangle \]
 通用性意味着，任何配备了满足余楔条件的箭头族$g_x \colon P \langle x, x \rangle \to d$的对象$d$，都会有一个唯一的从余极限映射出的映射：
 \[ h \colon \int^{x\colon \mathcal{C}} P \langle x, x \rangle \to d \]
 可以通过注入$i_x$因式分解所有的$g_x$：
 \[ g_x = h \circ i_x \]
 如图所示：
 \[
  \begin{tikzcd}
   &P \langle y, x \rangle
   \arrow[ld, "{P \langle id, f \rangle}"']
   \arrow[rd, "{P \langle f, id \rangle}"]
   \\
   P \langle y, y \rangle
   \arrow[dr, "i_y"']
   \arrow[ddr, bend right,  "g_y"']
   &&P \langle x, x \rangle
   \arrow[dl, "i_x"]
   \arrow[ddl, bend left,  "g_x"]
   \\
   &\int^x P \langle x, x \rangle
   \arrow[d, dashed, "h"]
   \\
   &d
  \end{tikzcd}
 \]

 将其与两个对象之和的定义进行比较：

 \[
  \begin{tikzcd}
   a
   \arrow[dr, "\text{Left}"]
   \arrow[ddr, bend right, "f"']
   && b
   \arrow[dl, "\text{Right}"']
   \arrow[ddl, bend left, "g"]
   \\
   &a + b
   \arrow[d, dashed, "h"]
   \\
   & d
  \end{tikzcd}
 \]
 正如和被定义为通用的余图形（cospan），余极限被定义为通用的余楔形图。

 特别是，如果你要构造一个$\Set$值泛函的余极限，你会从所有集合$P \langle x, x \rangle$的和（带鉴别的并集）开始。然后你会识别出所有满足余楔条件的和元素。你会将$P \langle x, x \rangle$中的元素$a$与$P \langle y, y \rangle$中的元素$b$相识别，每当存在$P \langle y, x \rangle$中的元素$c$和态射$f \colon x \to y$，使得：
 \[ P \langle id, f \rangle (c) = b\]
 且
 \[ P \langle f, id \rangle (c) = a\]

 请注意，在离散范畴中（它只是一个对象集，不存在它们之间的箭头），余楔条件是平凡的（除了恒等箭头外没有其他$f$），所以余极限只是对角对象$P \langle x, x \rangle$的直接和（余并）。

 \subsection{Extranatural transformations（超自然变换）}

 在目标范畴中由源范畴的对象参数化的箭头族通常可以合并为两个函子之间的单一自然变换。

 在余楔的定义中，注入构成了一个由对象参数化的函数族，但它们不能很好的契合自然变换的定义。
 \[
  \begin{tikzcd}
   P \langle y, y \rangle
   \arrow[dr, "i_y"']
   \arrow[rr, dash, dashed]
   &&P \langle x, x \rangle
   \arrow[dl, "i_x"]
   \\
   &d
  \end{tikzcd}
 \]
 问题在于函子$P \colon \cat C^{op} \times \cat C \to \cat D$在第一个参数中是反变的，在第二个参数中是协变的；因此，其对角部分在对象上定义为$x \mapsto P \langle x, x \rangle$，但它并非自然变换。

 我们可以利用的最接近的自然性（naturality）是余楔条件：
 \[
  \begin{tikzcd}
   &P \langle y, x \rangle
   \arrow[ld, "{P \langle id, f \rangle}"']
   \arrow[rd, "{P \langle f, id \rangle}"]
   \\
   P \langle y, y \rangle
   \arrow[dr, "i_y"']
   &&P \langle x, x \rangle
   \arrow[dl, "i_x"]
   \\
   &d
  \end{tikzcd}
 \]
 的确，与自然性方块一样，它涉及的是态射$f \colon x \to y$的提升（这里有两种不同的方式）与变换$i$的分量之间的交互。

 当然，标准的自然性条件涉及的是函子对。在这里，变换的目标是一个固定的对象$d$。但我们总是可以将其重新解释为常量泛函$\Delta_d \colon \cat C^{op} \times \cat C \to \cat D$的输出。因此，为了推广自然性，我们将$\Delta_d$替换为任意泛函$Q$。

 我们将余楔条件重新解释为更一般的\emph{超自然变换}（extranatural transformation）的特例。超自然变换是一个箭头族：
 \[ \alpha_{c d} \colon P \langle c, c \rangle \to Q \langle d, d \rangle \]
 在两个函子之间：
 \[ P \colon \cat C^{op} \times \cat C \to \cat E \]
 \[ Q \colon \cat D^{op} \times \cat D \to \cat E \]
 在$c$中的超自然性意味着，对于任何态射$f \colon c \to c'$，以下图表交换：
 \[
  \begin{tikzcd}
   &P \langle c', c \rangle
   \arrow[ld, "{P \langle id, f \rangle}"']
   \arrow[rd, "{P \langle f, id \rangle}"]
   \\
   P \langle c', c' \rangle
   \arrow[dr, "\alpha_{c' d}"']
   &&P \langle c, c \rangle
   \arrow[dl, "\alpha_{c d}"]
   \\
   & Q \langle d, d \rangle
  \end{tikzcd}
 \]
 在$d$中的超自然性意味着，对于任何态射$g \colon d \to d'$，以下图表交换：
 \[
  \begin{tikzcd}
   &P \langle c, c \rangle
   \arrow[ld, "\alpha_{c d}"']
   \arrow[rd, "\alpha_{c d'}"]
   \\
   Q \langle d, d \rangle
   \arrow[dr, "{Q \langle id, g\rangle}"']
   &&Q \langle d', d' \rangle
   \arrow[dl, "{Q \langle g,  id\rangle}"]
   \\
   & Q \langle d, d' \rangle
  \end{tikzcd}
 \]

 基于此定义，我们可以将余楔条件重新解释为从泛函$P$到常量泛函$\Delta_d$的映射的超自然性。

 现在我们可以将余极限定义为对$(c, i)$的配对，其中$c$是配备了从$P$到$\Delta_c$的超自然变换$i$的对象，并且在此类对中是通用的。

 通用性意味着，对于任何配备了从$P$到$\Delta_d$的超自然变换$\alpha$的对象$d$，存在一个唯一的态射$h \colon c \to d$，它通过$i$的所有分量对$\alpha$的所有分量进行因式分解：
 \[ \alpha_x = h \circ i_x \]
 我们将这个对象$c$称为余极限，并将其写为：
 \[ c = \int^x P\langle x, x \rangle \]

 \begin{exercise}
  验证对于从$P$到$\Delta_d$的超自然变换，第一个超自然性菱形等价于余楔条件，第二个条件是平凡的。
 \end{exercise}

 \subsection{Profunctor composition using coends（使用余极限的泛函组合）}

 有了余极限的定义，我们现在可以正式定义两个泛函的组合：

 \[ (P \diamond Q)\langle a, b \rangle = \int^{x\colon \mathcal{C}} Q \langle a, x \rangle \times P \langle x, b \rangle\]
 将其与以下内容进行比较：
 \begin{haskell}
  data Procompose p q a b where
  Procompose ::  q a x -> p x b -> Procompose p q a b
 \end{haskell}

 在Haskell中我们不需要担心余楔条件的原因类似于所有参数多态函数自动满足自然性条件的原因。余极限是使用箭头族定义的；在Haskell中，所有这些注入都是由\emph{单个}多态函数定义的：
 \begin{haskell}
  data Coend p where
  Coend ::  p x x -> Coend p
 \end{haskell}
 \emph{参数多态性}（parametricity）然后强制执行余楔条件。

 余极限在处理泛函时引入了一个新的抽象层次。使用余极限进行计算通常利用其映射出属性。要定义从余极限到某个对象$d$的映射：
 \[ \int^x P \langle x, x \rangle \to d \]
 只需定义从函子的对角项到$d$的一族函数：
 \[ g_x \colon P \langle x, x \rangle \to d \]
 满足余楔条件。这个技巧结合Yoneda引理可以带来很大的好处。我们将在接下来的内容中看到一些例子。

 \begin{exercise}
  为以下泛函对定义一个\hask{Profunctor}实例：
  \begin{haskell}
   newtype ProPair q p a b x y = ProPair (q a y, p x b)
  \end{haskell}
  提示：保持前四个参数固定：
  \begin{haskell}
   instance (Profunctor p, Profunctor q) => Profunctor (ProPair q p a b)
  \end{haskell}
 \end{exercise}

 \begin{exercise}
  泛函组合可以使用余极限表示：
  \begin{haskell}
   newtype CoEndCompose p q a b = CoEndCompose (Coend (ProPair q p a b))
  \end{haskell}
  为\hask{CoEndCompose}定义一个\hask{Profunctor}实例。
 \end{exercise}

 \subsection{Colimits as coends（作为余极限的余极限）}
 一个忽略其参数之一的二元函数等价于一个一元函数。类似地，一个忽略其参数之一的泛函等价于一个函子。反过来，给定一个函子$F$，我们可以构造一个平凡的泛函。它在对象上的作用由以下公式给出：
 \[P \langle x, y \rangle = F y \]
 它在箭头对上的作用忽略了其中一个箭头：
 \[P \langle f, g \rangle = F g \]

 对于任意$f \colon x \to y$，我们这种泛函的余极限的定义简化为以下图表：
 \[
  \begin{tikzcd}
   & F x
   \arrow[ld, "F f"']
   \arrow[rd, dashed, "id_{F x}"]
   \\
   F y
   \arrow[dr, "i_y"']
   \arrow[ddr, bend right,  "g_y"']
   && F x
   \arrow[dl, "i_x"]
   \arrow[ddl, bend left,  "g_x"]
   \\
   &\int^x F x
   \arrow[d, dashed, "h"]
   \\
   &d
  \end{tikzcd}
 \]
 在缩小恒等箭头之后，原始的余楔形图变成了余锥形图（co-cone），通用条件变成了余极限的定义。这就证明了将余极限符号用于余极限的合理性：
 \[ \int^x F x = \text{colim} F \]
 函子$F$定义了目标范畴中的一个图形。这个模式是整个源范畴。

 如果我们考虑一个离散范畴，其中泛函是一个（可能是无限的）矩阵，余极限是其对角线元素的和（余并）。沿着一条轴恒定的泛函对应于每一行相同的矩阵（每行由一个向量$F x$给出）。这样的矩阵的对角线元素之和等于向量$F x$的所有元素之和。
 \[
  \begin{pmatrix}
   \color{red} F a & F b & F c & ... \\
   F a & \color{red}F b & F c & ...\\
   F a & F b &\color{red}F c & ...\\
   ... & ... & ... & ...
  \end{pmatrix}
 \]
 在非离散范畴中，这个和则推广为余极限。


\section{Ends}

Just like a coend generalizes the sum of the diagonal elements of a profunctor---its dual, an end, generalizes the product. A product is defined by its projections, and so is an end. 

The generalization of a span that we used in the definition of a product would be an object $d$ with a family of projections, one per every object $x$:
\[ \pi_x \colon d \to P \langle x, x \rangle \]
The dual to a co-wedge is called a \index{wedge}wedge:
\[
 \begin{tikzcd}
 &d
 \arrow[ld, "\pi_x"']
 \arrow[rd, "\pi_y"]
 \\
 P \langle x, x \rangle
 \arrow[dr, "{P \langle id, f \rangle}"']
 &&P \langle y, y \rangle
 \arrow[dl, "{P \langle f, id \rangle}"]
 \\
 & P \langle x, y \rangle
 \end{tikzcd}
\]
For every arrow $f \colon x \to y$ we demand that:
\[ P \langle f, id_y \rangle \circ \pi_y = P \langle id_x, f \rangle \circ \pi_x \]

The end is a universal wedge. We use the integral sign for it too, this time with the ``integration variable'' at the bottom. 
\[ \int_{x \colon \cat C} P \langle x, x \rangle \]

You might be wondering why, in calculus, integrals based on multiplication rather than summation are rarely used. That's because we can always use a logarithm to replace multiplication with addition. We don't have this luxury in category theory, so ends and coends are equally important.

To summarize, an end is an object equipped with a family of morphisms (projections):
\[ \pi_a \colon \left( \int_x P \langle x, x \rangle \right) \to P \langle a, a \rangle \]
satisfying the wedge condition. 

It is universal among such objects; that is, for any other object $d$ equipped with a family of arrows $g_x$ satisfying the wedge condition, there is a unique morphism $h$ that factorizes the family $g_x$ through the family $\pi_x$:
\[ g_x = \pi_x \circ h \]
Pictorially, we have:
\[
 \begin{tikzcd}
 &d
 \arrow[ddl, bend right, "g_x"']
 \arrow[ddr, bend left, "g_y"]
 \arrow[d, dashed, "h"]
 \\
 & \int_x P \langle x, x \rangle
 \arrow[ld, "\pi_x"']
 \arrow[rd, "\pi_y"]
 \\
 P \langle x, x \rangle
 \arrow[dr, "{P \langle id, f \rangle}"']
 &&P \langle y, y \rangle
 \arrow[dl, "{P \langle f, id \rangle}"]
 \\
 & P \langle x, y \rangle
 \end{tikzcd}
\]

Equivalently, we can say that the end is a pair $(e, \pi)$ consisting of an object $e = \int_x P\langle x, x\rangle$ and an  \index{extranatural transformation}extranatural transformation $\pi \colon \Delta_d \to e$ that is universal among such pairs. The wedge condition turns out to be a special case of extranaturality condition.

If you were to construct an end of a $\Set$-valued profunctor, you'd start with a giant product of all $P \langle x, x \rangle$ for all objects in the category $\cat C$, and then prune the tuples that don't satisfy the wedge condition. 

In particular, imagine using the singleton set $1$ in place of $d$. The family $g_x$ would select one element from each set $P \langle x, x \rangle$. This would give you a giant tuple. You'd weed out most of these tuples, leaving only the ones that satisfy the wedge condition. 

Again, in Haskell, due to \index{parametricity}parametricity, the wedge condition is automatically satisfied, and the definition of the end for a profunctor \hask{p} simplifies to:

\begin{haskell}
type End p = forall x. p x x
\end{haskell}

The Haskell implementation of an \hask{End} doesn't showcase the fact that it is dual to the \hask{Coend}. This is because, at the time of this writing, Haskell doesn't have a built-in syntax for existential types. If it did, the \hask{Coend} would be implemented as:
\begin{haskell}
type Coend p = exists x. p x x
\end{haskell}

The existential/universal duality between a \hask{Coend} and an \hask{End} means that it's easy to construct a \hask{Coend}---all you need is to pick one type \hask{x} for which you have a value of the type \hask{p x x}. On the other end, to construct an \hask{End} you have to provide a whole family of values \hask{p x x}, one for every type \hask{x}. In other words, you need a polymorphic formula that is parameterized by \hask{x}. A definition of a polymorphic function is a canonical example of such a formula.


\subsection{Natural transformations as an end}

The most interesting application of an end is in concisely defining the set of natural transformations. Consider two functors, $F$ and $G$, going between two categories  $\mathcal{B}$ and $\mathcal{C}$. A natural transformation between them is a family of arrows $\alpha_x$ in $\mathcal{C}$. You may think of it as picking one element $\alpha_x$ from each hom-set  $\mathcal{C} (F x, G x)$.
\[
 \begin{tikzcd}
 && F x
 \arrow[dd, "{\alpha_x \in \cat C (F x, G x)}"]
 \\
 x
 \arrow[urr, dashed, "F"]
 \arrow[drr, dashed, "G"]
 \\
 && G x
 \end{tikzcd}
\]

We know that the mapping $\langle a, b \rangle \to \mathcal{C} (a, b)$ defines a profunctor.  It turns out that, for any pair of functors, the mapping  $\langle a, b \rangle \to \mathcal{C} (F a, G b)$ also behaves like a profunctor. The action of this profunctor on a pair of arrows $\langle f \colon s \to a, g \colon b \to t \rangle$ is a function:
\[ \cat C(F a, G b) \to \cat C (F s, G t) \]
given by the composition:
\[ F s \xrightarrow{F f} F a \xrightarrow{h} G b \xrightarrow{G g} G t \]
where $h$ is an  element of $ \mathcal{C} (F a, G b)$.

The diagonal parts of this profunctor are perfect candidates for the components of a natural transformation. In fact, the end:
\[  \int_{x \colon  \mathcal{B}} \mathcal{C}(F x, G x) \]
defines a set of natural transformations from $F$ to $G$.

To show this, let's check the wedge condition. Plugging in our profunctor, we get:

\[
 \begin{tikzcd}
 & \int_{x} \mathcal{C}(F x, G x)
 \arrow[ld, "\pi_a"']
 \arrow[rd, "\pi_b"]
 \\
  \mathcal{C} ( F a, G a )
 \arrow[dr, "{(Ff \, \circ \, -)}"']
 && \mathcal{C} \langle F b, G b \rangle
 \arrow[dl, "{(- \, \circ\, Gf)}"]
 \\
 &  \mathcal{C} ( F a, G b )
 \end{tikzcd}
\]

We can pick a single element of the set $\int_{x} \mathcal{C}(F x, G x)$ by instantiating the universal condition for the singleton set:

\[
 \begin{tikzcd}
 & 1
 \arrow[d, dashed, "\alpha"]
\arrow[ddl, bend right, "\alpha_a"']
 \arrow[ddr, bend left, "\alpha_b"]
 \\
 & \int_{x} \mathcal{C}(F x, G x)
 \arrow[ld, "\pi_a"']
 \arrow[rd, "\pi_b"]
 \\
  \mathcal{C} ( F a, G a )
 \arrow[dr, "{(F f \, \circ \, -)}"']
 && \mathcal{C} \langle F b, G b \rangle
 \arrow[dl, "{(- \, \circ\, G f)}"]
 \\
 &  \mathcal{C} ( F a, G b )
 \end{tikzcd}
\]
We pick the component $\alpha_a$ from the hom-set $\mathcal{C} ( F a, G a )$ and the component $\alpha_b$ from $\mathcal{C} ( F b, G b )$. The wedge condition then boils down to:
\[ F f \circ \alpha_a = \alpha_b \circ G f \]
for any $f \colon a \to b$. This is exactly the naturality condition. So any element $\alpha$ of this end is automatically a natural transformation.

The set of natural transformations, or the hom-set in the functor category, is thus given by the end:
\[ [\mathcal{C}, \mathcal{D}] (F, G) \cong \int_{x \colon  \mathcal{B}} \mathcal{C}(F x, G x)\]

In Haskell, this is consistent with our earlier definition:
\begin{haskell}
type Natural f g = forall x. f x -> g x
\end{haskell}

As we discussed earlier, to construct an \hask{End} we have to give it a whole family of values parameterized by types. Here, these values are the components of a polymorphic function. 

\subsection{Limits as ends}
Just like we were able to express colimits as coends, we can express limits as ends. As before, we define a trivial profunctor that ignores its first argument:
\begin{align*}
 P \langle x, y \rangle &= F y \\
 P \langle f, g \rangle &= F g 
\end{align*}
The universal condition that defines an end becomes the definition of a universal cone:
\[
 \begin{tikzcd}
 &d
 \arrow[ddl, bend right, "g_x"']
 \arrow[ddr, bend left, "g_y"]
 \arrow[d, dashed, "h"]
 \\
 & \int_x F x
 \arrow[ld, "\pi_x"']
 \arrow[rd, "\pi_y"]
 \\
 F x
 \arrow[dr, "F f"']
 &&F y
 \arrow[dl, dashed, "id_{F y}"]
 \\
 & F y
 \end{tikzcd}
\]
We can thus use the end notation for limits:
\[ \int_x F x = \text{lim} F \]

\begin{exercise}
A product is a limit of a functor from a two-object category $\Cat 2$. Show that it can be defined as an end. Hint: There are no non-identity morphisms in $\Cat 2$.
\end{exercise}

\section{Continuity of the Hom-Functor}

In category theory, a functor $F$ is called \index{continuous functor}\emph{continuous} if it preserves limits (and co-continuous, if it preserves colimits). It means that, if you have a diagram in the source category, it doesn't matter if you first use $F$ to map the diagram and then take the limit in the target category, or take the limit in the source category and then use $F$ to map this limit. 

The hom-functor is an example of a functor that is continuous in its second argument. Since a product is the simplest example of a limit, this means, in particular, that:
\[ \mathcal{C}(x, a \times b) \cong \mathcal{C}(x, a) \times \mathcal{C}(x, b) \]
The left hand side applies the hom-functor to the product (a limit of a span). The right hand side maps the diagram, here just a pair of objects, and takes the product (limit) in the target category. The target category for the hom-functor is $\mathbf{Set}$, so this is just a cartesian product. The two sides are isomorphic by the universal property of the product: the mapping into the product is defined by a pair of mappings into the two objects. 

Continuity of the hom-functor in the first argument is reversed: it maps colimits to limits. Again, the simplest example of a colimit is the sum, so we have:
\[ \mathcal{C}(a + b, x) \cong \mathcal{C}(a, x) \times \mathcal{C}(b, x) \]
This follows from the universality of the sum: a mapping out of the sum is defined by a pair of mapping out of the two objects.

It can be shown that an end can be expressed as a limit, and a coend as a colimit. Therefore, by continuity of the hom-functor, we can always pull out the integral sign from inside a hom-set. By analogy with the product, we have the mapping-in formula for an end:
\[\cat D\left(d, \int_a P\langle a, a \rangle \right) \cong \int_a \cat D(d, P\langle a, a \rangle) \]
By analogy with the sum, we have a mapping-out formula for the coend:
\[\cat D\left( \int^a P\langle a, a \rangle , d \right) \cong \int_a \cat D(P\langle a, a \rangle, d) \]
Notice that, in both cases, the right-hand side is an end.

\section{Fubini Rule}

The Fubini rule in calculus states the conditions under which we can switch the order of integration in double integrals. It turns out that we can similarly switch the order of double ends and coends. The \index{Fubini rule}Fubini rule for ends works for functors of the form $P \colon \cat C \times \cat C^{op} \times \cat D \times \cat D^{op} \to \cat E$. The following expressions, as long as they exist, are isomorphic:
\[ \int_{c \colon \cat C} \int_{d \colon \cat D} P\langle c, c \rangle \langle d, d \rangle \cong  \int_{d \colon \cat D} \int_{c \colon \cat C} P\langle c, c \rangle \langle d, d \rangle \cong  \int_{\langle c, d \rangle \colon \cat C \times \cat D}  P\langle c, c \rangle \langle d, d \rangle \]
In the last end, the functor $P$ is reinterpreted as $P \colon (\cat C  \times \cat D)^{op} \times (\cat C \times \cat D)\to \cat E$

The analogous rule works for coends as well.

\section{Ninja Yoneda Lemma}

Having expressed the set of natural transformations as an end, we can now rewrite the Yoneda lemma. This is the original formulation:
\[ [\mathcal{C}, \mathbf{Set}]( \mathcal{C}(a, -), F) \cong F a \]
Here, $F$ is a (covariant) functor from $\mathcal{C}$ to $\mathbf{Set}$ (a co-presheaf), and so is the hom-functor $\mathcal{C}(a, -)$. 
Expressing the set of natural transformations as an end we get:
\[ \int_{x \colon \mathcal{C}} \mathbf{Set} (\mathcal{C}(a, x), F x) \cong F a \]

Similarly, we have the Yoneda lemma for a contravariant functor (a presheaf) $G$:
\[ \int_{x \colon \mathcal{C}} \mathbf{Set} (\mathcal{C}(x, a), G x) \cong G a \]

These versions of the Yoneda lemma, expressed in terms of ends, are often half-jokingly called ninja-Yoneda lemmas. The fact that the ``integration variable'' is explicit makes them somewhat easier to use in complex formulas.

There is also a dual set of ninja co-Yoneda lemmas that use coends instead. For a covariant functor, we have:
\[ \int^{x \colon \mathcal{C}} \mathcal{C}(x, a) \times F x \cong F a \]
and for the contravariant one we have:
\[ \int^{x \colon \mathcal{C}} \mathcal{C}(a, x) \times G x \cong G a \]

Physicists might notice the similarity of these formulas to integrals involving the Dirac delta function---strictly speaking, a distribution. This is why profunctors are sometimes called \index{distributors}distributors, following the adage that ``distributors are to functors as distributions are to functions.'' Engineers might notice the similarity of the hom-functor to the impulse function.

This intuition is often expressed by saying that we can perform the ``integration over $x$'' in this formula, resulting in replacing $x$ with $a$ in the integrand $G x$. 

If $\cat C$ is a discrete category, the coend reduces to the sum (coproduct), and the hom-functor reduces to the unit matrix (the Kronecker delta). The co-Yoneda lemma then becomes:
\[ \sum_j \delta_i^j v_j = v_i \]
In fact, a lot of linear algebra translates directly to the theory of $\Set$-valued functors. You may often view such functors as vectors in a vector space, in which hom-functors form a basis. Profunctors become matrices and coends are used to multiply such matrices, calculate their traces, or multiply vectors by matrices.

Yet another name for profunctors, especially in Australia, is \index{bimodule}``bimodules.'' This is because the lifting of morphisms by a profunctor is somewhat similar to the left and right actions on sets. 

We'll now proceed with the proof of the co-Yoneda lemma, which is quite instructive, as it uses a few common tricks. Most importantly, we rely on the corollary of the Yoneda lemma, which says that, if all the mappings out from two objects to an arbitrary object are isomorphic, then the two objects are themselves isomorphic. In our case, we'll consider the mappings-out to an arbitrary set $S$ and show that:
\[ \mathbf{Set} \left(\int^{x \colon \mathcal{C}} \mathcal{C}(x, a) \times F x, S \right) \cong 
    \Set (F a, S)\]
Using the co-continuity of the hom-functor, we can pull out the integral sign, replacing the coend with an end:
\[ \int_{x \colon \mathcal{C}} \mathbf{Set} \left( \mathcal{C}(x, a) \times F x, S \right) \]
Since the category of sets is cartesian closed, we can curry the product:
\[ \int_{x \colon \mathcal{C}} \mathbf{Set} \left( \mathcal{C}(x, a) , S^{F x} \right) \]
We can now use the Yoneda lemma to ``integrate over $x$.'' The result is $S^{F a}$. Finally, in $\mathbf{Set}$, the exponential object is isomorphic to the hom-set:
\[S^{F a} \cong \mathbf{Set}(F a, S)\]
Since $S$ was arbitrary, we conclude that:
\[ \int^{x \colon \mathcal{C}} \mathcal{C}(x, a) \times F x \cong F a \]

\begin{exercise}
Prove the contravariant version of the co-Yoneda lemma.
\end{exercise}

\subsection{Yoneda lemma in Haskell}

We've already seen the Yoneda lemma implemented in Haskell. We can now rewrite it in terms of an end. We start by defining a profunctor that will go under the end. Its type constructor takes a functor \hask{f} and a type \hask{a} and generates a profunctor that's contravariant in \hask{x} and covariant in \hask{y}:
\begin{haskell}
data Yo f a x y = Yo ((a -> x) -> f y)
\end{haskell}
The Yoneda lemma establishes the isomorphism between the end over this profunctor and the type obtained by acting with the functor  \hask{f} on \hask{a}. This isomorphism is witnessed by a pair of functions:
\begin{haskell}
yoneda :: Functor f => End (Yo f a) -> f a
yoneda (Yo g) = g id

yoneda_1 :: Functor f => f a -> End (Yo f a)
yoneda_1 fa = Yo (\h -> fmap h fa)
\end{haskell}

Similarly, the co-Yoneda lemma uses a coend over the following profunctor:
\begin{haskell}
data CoY f a x y = CoY (x -> a) (f y)
\end{haskell}
The isomorphism is witnessed by a pair of functions. The first one says that if you have a function \hask{x -> a} and a functorful of \hask{x} then you can make a functorful of \hask{a} using the \hask{fmap}:
\begin{haskell}
coyoneda :: Functor f => Coend (CoY f a) -> f a
coyoneda (Coend (CoY g fa)) = fmap g fa
\end{haskell}
You can do it without knowing anything about the existential type \hask{x}.

The second says that if you have a functorful of \hask{a}, you can create a coend by injecting it (together with the identity function) into the existential type:
\begin{haskell}
coyoneda_1 :: Functor f => f a -> Coend (CoY f a)
coyoneda_1 fa = Coend (CoY id fa)
\end{haskell}

\section{Day Convolution}

Electrical engineers are familiar with the idea of convolution. We can convolve two streams by shifting one of them and summing its product with the other one: 
\[ (f \star g)(x) = \int^{\infty}_{-\infty} f(y) g(x - y) dy \]
This formula can be translated almost verbatim to category theory. We can start by replacing the integral with a coend. The problem is, we don't know how to subtract objects. We do however know how to add them, in a co-cartesian category. 

Notice that the sum of the arguments to the two functions is equal to $x$. We could enforce this condition by introducing the Dirac delta function or the ``impulse function,'' $\delta(a + b - x)$. In category theory we use the hom-functor $\cat C (a + b, x)$ to do the same. Thus we can define a convolution of two $\Set$-valued functors:
\[ (F \star G) x = \int^{a, b} \cat C (a + b, x) \times F a \times G b \]
Informally, if we could define subtraction as the right adjoint to coproduct, we'd write:
\[ \int^{a, b} \cat C (a + b, x) \times F a \times G b \cong \int^{a, b} \cat C (a, b - x) \times F a \times G b \cong \int^b F (b - x) \times G b\]

There is nothing special about coproduct so, in general, Day convolution is defined in any monoidal category with a tensor product:
\[ (F \star G) x = \int^{a, b} \cat C (a \otimes b, x) \times F a \times G b \]

In fact, Day convolution for a monoidal category $(\cat C, \otimes, I)$ endows the category of co-presheaves $[\cat C, \Set]$ with a monoidal structure. Simply said, if you can multiply objects in $\cat C$, you can multiply set-valued functors on $\cat C$.

It's easy to check that Day convolution is associative (up to isomorphism) and that $\cat C(I, -)$ serves as the unit object. For instance, we have:
\[ (\cat C(I, -) \star G) x =  \int^{a, b} \cat C (a \otimes b, x) \times \cat C(I, a) \times G b \cong 
  \int^{b} \cat C (I \otimes b, x) \times  G b \cong G x\]
So the unit of Day convolution is the Yoneda functor taken at monoidal unit, which lends itself to the anagrammatic slogan, ``ONE of DAY is the YONEDA of ONE.''

If the tensor product is symmetric, then the corresponding Day convolution is also symmetric (up to isomorphism).

In the special case of a cartesian closed category, we can use the currying adjunction to simplify the formula:
\[ (F \star G) x = \int^{a, b} \cat C (a \times b, x) \times F a \times G b \cong  \int^{a, b} \cat C (a, x^b) \times F a \times G b \cong  \int^{b}  F (x^b) \times G b\]

In Haskell, the product-based Day convolution can be defined using an existential type:
\begin{haskell}
data Day f g x where
  Day :: ((a, b) -> x) -> f a -> g b -> Day f g x
\end{haskell}

If we think of functors as containers of values, Day convolution tells us how to combine two different containers into one---given a function that combines two different values into one. 

\begin{exercise}
Define the \hask{Functor} instance for \hask{Day}.
\end{exercise}

\begin{exercise}
Implement the associator for \hask{Day}.
\begin{haskell}
assoc :: Day f (Day g h) x -> Day (Day f g) h x
\end{haskell}
\end{exercise}


\subsection{Applicative functors as monoids}
 
 We've seen before the definition of applicative functors as lax monoidal functors. It turns out that, just like monads, applicative functors can also be defined as monoids. 
 
Recall that a monoid is an object in a monoidal category. The category we're interested in is the co-presheaf category $[\cat C, \Set]$. If $\cat C$ is cartesian, then the co-presheaf category is monoidal with respect to Day convolution, with the unit object $\cat C(I, -)$. A monoid in this category is a functor $F$ equipped with two natural transformations that serve as unit and multiplication:
\[ \eta \colon \cat C(I, -) \to F \]
\[ \mu \colon F \star F \to F \]
In particular, in a cartesian closed category where the unit is the terminal object, $\cat C(1, a)$ is isomorphic to $a$, and the component of the unit at $a$ is:
\[ \eta_a \colon a \to F a \] 
You may recognize this function as \hask{pure} in the definition of \hask{Applicative}.
\begin{haskell}
pure :: a -> f a
\end{haskell}

Let's consider the set of natural transformations from which $\mu$ is taken. We'll write it as an end:
\[ \mu \in \int_x \Set \big( (F \star F) x, F x \big) \]
Pluggin in the definition of Day convolution, we get:
\[ \int_x \Set \big( \int^{a, b} \cat C (a \times b, x) \times F a \times  F b, F x \big) \]
We can pull out the coend using co-continuity of the hom-functor:
\[ \int_{x, a, b} \Set \big( \cat C (a \times b, x) \times F a \times  F b, F x \big) \]
We can then use the currying adjunction in $\Set$ to obtain:
\[ \int_{x, a, b} \Set \big( \cat C (a \times b, x),  \Set( F a \times  F b, F x) \big) \]
Finally, we apply the Yoneda lemma to perform the integration over $x$:
\[ \int_{a, b}  \Set \big( F a \times  F b, F (a \times b) \big) \]
The result is the set of natural transformations from which to select the second part of the lax monoidal functor:
\begin{haskell}
  (>*<) :: f a -> f b -> f (a, b)
\end{haskell}

\subsection{Free Applicatives}

We have just learned that applicative functors are monoids in the monoidal category:
\[ ([\cat C, \Set], \cat C(I, -), \star) \]
It's only natural to ask what a free monoid in that category is. 

Just like we did with free monads, we'll construct a free applicative as the initial algebra, or the least fixed point of the list functor. Recall that the list functor was defined as:
\[ \Phi_a x = 1 + a \otimes x \]
In our case it becomes:
\[ \Phi_F G = \cat C(I, -) + F \star G \]
Its fixed point is given by the recursive formula:
\[ A_F \cong \cat C(I, -) + F \star A_F\]

When translating this to Haskell, we observe that functions from the unit \hask{()->a} are isomorphic to elements of \hask{a}. 

Corresponding to the two addends in the definition of $A_F$, we get two constructors:
\begin{haskell}
data FreeA f x where
  DoneA :: x -> FreeA f x
  MoreA :: ((a, b) -> x) -> f a -> FreeA f b -> FreeA f x
\end{haskell}
I have inlined the definition of Day convolution:
\begin{haskell}
data Day f g x where
  Day :: ((a, b) -> x) -> f a -> g b -> Day f g x
\end{haskell}

The easiest way to show that \hask{FreeA f} is an applicative functor is to go through \hask{Monoidal}:
\begin{haskell}
class Monoidal f where
  unit  :: f ()
  (>*<) :: f a -> f b -> f (a, b)
\end{haskell}

Since \hask{FreeA f} is a generalization of a list, the \hask{Monoidal} instance for free applicative generalizes the idea of list concatenation. We do the pattern matching on the first list, resulting in two cases.

In the first case, instead of an empty list we have \hask{DoneA x}. Prepending it to the second argument doesn't change the length of the list, but it modifies the type of the values stored in it. It pairs each of them with \hask{x}:
\begin{haskell}
  (DoneA x) >*< fry = fmap (x,) fry
\end{haskell}

The second case is a ``list'' whose head \hask{fa} is a functorful of \hask{a}'s, and the tail \hask{frb} is of the type \hask{FreeA f b}. The two are glued using a function \hask{abx :: (a, b) -> x}. 
\begin{haskell}
  (MoreA abx fa frb) >*< fry = MoreA (reassoc abx) fa (frb >*< fry)
\end{haskell}
To produce the result, we concatenate the two tails using the recursive call to \hask{>*<} and prepend \hask{fa} to it. To glue this head to the new tail we have to provide a function that re-associates the pairs:
\begin{haskell}
reassoc :: ((a, b)-> x) -> (a, (b, y)) -> (x, y)
reassoc abx (a, (b, y)) = (abx (a, b), y)
\end{haskell}

The complete instance is thus:
\begin{haskell}
instance Functor f => Monoidal (FreeA f) where
  unit = DoneA ()
  (DoneA x) >*< fry = fmap (x,) fry
  (MoreA abx fa frb) >*< fry = MoreA (reassoc abx) fa (frb >*< fry)
\end{haskell}

Once we have the \hask{Monoidal} instance, it's straightforward to produce the \hask{Applicative} instance:
\begin{haskell}
instance Functor f => Applicative (FreeA f) where
  pure a = DoneA a
  ff <*> fx = fmap app (ff >*< fx)
  
app :: (a -> b, a) -> b
app (f, a) = f a
\end{haskell}

\begin{exercise}
Define the \hask{Functor} instance for the free applicative.
\end{exercise}


\section{The Bicategory of Profunctors}

Since we know how to compose profunctors using coends, the question arises: is there a category in which they serve as morphisms? The answer is yes, as long as we relax the rules a bit. The problem is that the categorical laws for profunctor composition are nor satisfied ``on the nose,'' but only up to isomorphism. 

For instance, we can try to show associativity of profunctor composition. We start with:
\[ ((P \diamond Q) \diamond R) \langle s, t \rangle = \int^b \left( \int^a P \langle s, a \rangle \times Q \langle a, b \rangle \right) \times R \langle b,  t \rangle \]
and, after a few transformations, arrive at:
\[ (P \diamond (Q \diamond R)) \langle s, t \rangle =  \int^a P \langle s, a \rangle \times \left( \int^b Q \langle a, b \rangle \times R \langle b,  t \rangle \right) \]
We use the associativity of the product and the fact that we can switch the order of coends using the Fubini theorem. Both are true only up to isomorphism. We don't get associativity ``on the nose.''

The identity profunctor turns out to be the hom-functor, which can be written symbolically as $\mathcal{C}(-, =)$, with placeholders for both arguments. For instance:
\[ \left( \mathcal{C}(-, =) \diamond P \right) \langle s, t \rangle = \int^a  \mathcal{C}(s, a) \times P \langle a, t \rangle \cong P \langle s, t \rangle \]
This is the consequence of the (contravariant) ninja co-Yoneda lemma, which is also an isomorphism, not an equality.

A category in which categorical laws are satisfied up to isomorphism is called a \index{bicategory}bicategory. Notice that such a category must be equipped with 2-cells---morphisms between morphisms, which we've already seen in the definition of a 2-category. We need those in order to be able to define isomorphisms between 1-cells. 

A bicategory $\mathbf{Prof}$ has (small) categories as objects, profunctors as 1-cells, and natural transformations as 2-cells. 

Since profunctors are functors $\mathcal{C}^{op} \times  \mathcal{D} \to \mathbf{Set}$, the standard definition of natural transformations between them applies. It's a family of functions parameterized by objects of $\mathcal{C}^{op} \times  \mathcal{D}$, which are themselves pairs of objects. 

The naturality condition for a transformation $\alpha_{\langle a, b \rangle}$ between two profunctors $P$ and $Q$ takes the form:
\[
 \begin{tikzcd}
 &P \langle a, b \rangle
 \arrow[ld, "{\alpha_{\langle a, b \rangle}}"']
 \arrow[rd, "{P \langle f, g \rangle}"]
 \\
 Q \langle a, b \rangle
 \arrow[dr, "{Q \langle f, g \rangle}"']
 &&P \langle s, t \rangle
 \arrow[dl, "{\alpha_{\langle s, t \rangle}}"]
 \\
 & Q \langle s, t \rangle
 \end{tikzcd}
\]
for every pair of arrows:
\[ \langle f \colon s \to a, g \colon b \to t \rangle \]

\subsection{Monads in a bicategory}

We've seen before that categories, functors, and natural transformations form a 2-category $\Cat{Cat}$. Let's focus on one object, a category $\cat C$, that is a 0-cell in $\Cat{Cat}$. The 1-cells that start and end at this object form a regular category, in this case it's the functor category $[\cat C, \cat C]$. The objects in this category are endo-1-cells of the outer 2-category $\Cat{Cat}$. The arrows between them are the 2-cells of the outer 2-category.

This endo-one-cell category is automatically equipped with monoidal structure. We simply define the tensor product as the composition of 1-cells---all 1-cells with the same source and target compose. The monoidal unit object is the identity 1-cell, $I$. In $[\cat C, \cat C]$ this product is the composition of endofunctors and the unit is the identity functor. 

If we now focus our attention on just one endo-1-cell $F$, we can ``square'' it, that is use the monoidal product to multiply it by itself. In other words, use the 1-cell composition to create $F \circ F$. We say that $F$ is a monad if we can find 2-cells:
\[ \mu \colon F \circ F \to F \]
\[ \eta \colon I \to F \]
that behave like multiplication and unit, that is they make the associativity and unit diagrams commute. 
\[
   \begin{tikzpicture}
        \node [] (star) {$\cat C$} ;
        \path[->,draw] (star) to  [in=45,out=135, loop,distance=2cm] node[ below] {$I$} (star);
        \path[->,draw] (star) to  [in=40,out=140, loop,distance=4cm] node[above] {$F$} (star);
        \path[->,draw] (star) to  [ in=35,out=145, loop,distance=7cm] node[auto] {$F \circ F$} (star);
    \end{tikzpicture}
\]
In fact a monad can be defined in an arbitrary bicategory, not just the 2-category $\Cat{Cat}$. 

\subsection{Prearrows as monads in $\Cat{Prof}$}

Since $\Cat{Prof}$ is a bicategory, we can define a monad in it. It is an endo-profunctor (a 1-cell):
\[ P \colon \cat C^{op} \times \cat C \to \Set \]
equipped with two natural transformations (2-cells):
\[ \mu \colon P \diamond P \to P \]
\[ \eta \colon \cat C(-, =) \to P \]
that satisfy the associativity and unit conditions.

Let's look at these natural transformations as elements of ends. For instance:
\[ \mu \in \int_{\langle a, b \rangle} \Set \big( \int^x P \langle a, x \rangle \times P \langle x, b \rangle,  P\langle a, b \rangle \big) \]
By co-continuity, this is equivalent to:
\[ \int_{\langle a, b \rangle, x} \Set \big(P \langle a, x \rangle \times P \langle x, b \rangle,  P\langle a, b \rangle \big) \]
Similarly, the unit natural transformation is:
\[ \eta \in \int_{\langle a, b \rangle} \Set (\cat C(a, b), P\langle a, b \rangle) \]

In Haskell, such profunctor monads are called pre-arrows:
\begin{haskell}
class Profunctor p => PreArrow p where
  (>>>) :: p a x -> p x b -> p a b
  arr   :: (a -> b) -> p a b
\end{haskell}
An \hask{Arrow} is a \hask{PreArrow} that is also a Tambara module. We'll talk about Tambara modules in the next chapter.

\section{Existential Lens}

The first rule of category-theory club is that you don't talk about the internals of objects.

The second rule of category-theory club is that, if you have to talk about the internals of objects, use arrows only.

\subsection{Existential lens in Haskell}

What does it mean for an object to be a composite---to have parts? At the very minimum, you should be able to retrieve a part of such an object. Even better if you can replace that part with a new one. This pretty much defines a lens:
\begin{haskell}
get :: s -> a
set :: s -> a -> s
\end{haskell}
Here, \hask{get} extracts the part \hask{a} from the whole \hask{s}, and \hask{set} replaces that part with a new \hask{a}. Lens laws help to reinforce this picture. And it's all done in terms of arrows. 

Another way of describing a composite object is to say that it can be split into a focus and a residue. The trick is that, although we want to know what type the focus is, we don't care about the type of the residue. All we need to know about the residue is that it can be combined with the focus to recreate the whole object. 

In Haskell, we would express this idea using an existential type:
\begin{haskell}
data LensE s a where
    LensE :: (s -> (c, a), (c, a) -> s) -> LensE s a
\end{haskell}
This tells us that there exists some unspecified type \hask{c}, such that \hask{s} can be split into, and reconstructed from, a product \hask{(c, a)}. 

\[
\begin{tikzpicture}
\filldraw[fill=gray!50, draw=white] (0, 0) circle (1.2);
\node at (0, -0.9) {$s$};
\end{tikzpicture}
\hspace{20pt}
\begin{tikzpicture}
\filldraw[fill=blue!50!green!20, draw=white] (0, 0) circle (1.2);
\filldraw[fill=orange!30, draw=white] (0, 0) circle (0.6);
\node at (0, 0) {$a$};
\node at (0, -0.9) {$c$};
\end{tikzpicture}
\]


The \hask{get}/\hask{set} version of the lens can be derived from this existential form.
\begin{haskell}
toGet :: LensE s a -> (s -> a)
toGet (LensE (l, r)) = snd . l

toSet :: LensE s a -> (s -> a -> s)
toSet (LensE (l, r)) s a = r (fst (l s), a)
\end{haskell}

Notice that we don't need to know anything about the type of the residue. We take advantage of the fact that the existential lens contains both the producer and the consumer of \hask{c} and we're just mediating between the two.

It's impossible to extract a ``naked'' residue, as witnessed by the fact that the following code doesn't compile:
\begin{haskell}
getResidue :: Lens s a -> c
getResidue (Lens (l, r)) = fst . l
\end{haskell}

\subsection{Existential lens in category theory}

We can easily translate the new definition of the lens to category theory by expressing the existential type as a coend:
\[ \int^{c} \mathcal{C}(s, c \times a) \times  \mathcal{C}(c \times a, s) \]
In fact, we can generalize it to a type-changing lens, in which the focus $a$ can be replaced with a new focus of a different type $b$. Replacing $a$ with $b$ will produce a new composite object $t$:
\[
\begin{tikzpicture}
\filldraw[fill=blue!50!green!20, draw=white] (0, 0) circle (1.2);
\filldraw[fill=orange!30, draw=white] (0, 0) circle (0.6);
\node at (0, 0) {$b$};
\node at (0, -0.9) {$c$};
\end{tikzpicture}
\hspace{20pt}
\begin{tikzpicture}
\filldraw[fill=gray!50, draw=white] (0, 0) circle (1.2);
\node at (0, -0.9) {$t$};
\end{tikzpicture}
\]

The lens is now parameterized by two pairs of objects: $\langle s, t\rangle$ for the outer ones, and $ \langle a, b \rangle$ for the inner ones. The existential residue $c$ remains hidden:
\[ \mathcal{L}\langle s, t\rangle \langle a, b \rangle = \int^{c} \mathcal{C}(s, c \times a) \times  \mathcal{C}(c \times b, t) \]
The product under the coend is the diagonal part of the profunctor that is covariant in $y$ and contravariant in $x$:
\[ \mathcal{C}(s, y \times a) \times  \mathcal{C}(x \times b, t) \]
\begin{exercise}
Show that:
\[ \mathcal{C}(s, y \times a) \times  \mathcal{C}(x \times b, t) \]
is a profunctor in $\langle x, y\rangle$.
\end{exercise}


\subsection{Type-changing lens in Haskell}
In Haskell, we can define a type-changing lens as the following existential type:
\begin{haskell}
data LensE s t a b where
  LensE :: (s -> (c, a)) -> ((c, b) -> t) -> LensE s t a b
\end{haskell}

As before, we can use the existential lens to get and set the focus:
\begin{haskell}
toGet :: LensE s t a b -> (s -> a)
toGet (LensE l r) = snd . l

toSet :: LensE s t a b -> (s -> b -> t)
toSet (LensE l r) s a = r (fst (l s), a)
\end{haskell}

The two functions, \hask{s->(c, a)} and \hask{(c, b)->t} are often called the \emph{forward} and the \emph{backward} pass. 
The forward pass can be used to extract the focus \hask{a}. The backward pass provides the answer to the question: If we wanted the result of the forward pass to be some other \hask{b}, what \hask{t} should we pass to it? 

And sometimes we're just asking: What change \hask{t} should we make to the input if we wanted to change the focus by \hask{b}. The latter point of view is especially useful when using lenses to describe \index{neural networks}neural networks.

The simplest example of a lens acts on a product. It can extract or replace one component of the product, treating the other as the residue. In Haskell, we'd implement it as:
\begin{haskell}
prodLens :: LensE (c, a) (c, b) a b
prodLens = LensE id id
\end{haskell}
Here, the type of the whole is the product \hask{(c, a)}. When we replace \hask{a} with \hask{b} we end up with the target type \hask{(c, b)}. Since the source and the target are already products, the two functions in the definition of the existential lens are just identities.

\subsection{Lens composition}

The main advantage of using lenses is that they compose. A composition of two lenses lets us zoom in on a subcomponent of a component. 

Suppose that we start with a lens that lets us access the focus \hask{a}  and change it to \hask{b}. This focus is part of a whole described by the source \hask{s} and the target \hask{t}. 

We also have the inner lens that can access the focus of \hask{a'}  inside the whole of \hask{a}, and replace it with \hask{b'} to give us a new \hask{b}. 

We can now construct a composite lens that can access \hask{a'} and \hask{b'} inside of \hask{s} and \hask{t}. The trick is to realize that we can take, as the new residue, a product of the two residues:
\[
\begin{tikzpicture}
\filldraw[fill=gray!50, draw=white] (0, 0) circle (1.4);
\node at (0, -1.1) {$s$};
\end{tikzpicture}
\hspace{20pt}
\begin{tikzpicture}
\filldraw[fill=blue!50!green!20, draw=white] (0, 0) circle (1.4);
\filldraw[fill=orange!30, draw=white] (0, 0) circle (0.9);
\node at (0, 0) {$a$};
\node at (0, -1.1) {$c$};
\end{tikzpicture}
\hspace{20pt}
\begin{tikzpicture}
\filldraw[fill=blue!50!green!20, draw=white] (0, 0) circle (1.4);
\filldraw[fill=orange!30, draw=white] (0, 0) circle (0.9);
\filldraw[fill=red!30, draw=white] (0, 0) circle (0.4);
\node at (0, 0) {$a'$};
\node at (0, -0.6) {$c'$};
\node at (0, -1.1) {$c$};
\end{tikzpicture}
\]

\[
\begin{tikzpicture}
\filldraw[fill=blue!50!green!20, draw=white] (0, 0) circle (1.4);
\filldraw[fill=orange!30, draw=white] (0, 0) circle (0.9);
\filldraw[fill=red!30, draw=white] (0, 0) circle (0.4);
\node at (0, 0) {$b'$};
\node at (0, -0.6) {$c'$};
\node at (0, -1.1) {$c$};
\end{tikzpicture}
\hspace{20pt}
\begin{tikzpicture}
\filldraw[fill=blue!50!green!20, draw=white] (0, 0) circle (1.4);
\filldraw[fill=orange!30, draw=white] (0, 0) circle (0.9);
\node at (0, 0) {$b$};
\node at (0, -1.1) {$c$};
\end{tikzpicture}
\hspace{20pt}
\begin{tikzpicture}
\filldraw[fill=gray!50, draw=white] (0, 0) circle (1.4);
\node at (0, -1.1) {$t$};
\end{tikzpicture}
\]



\begin{haskell}
compLens :: LensE a b a' b' -> LensE s t a b -> LensE s t a' b'
compLens (LensE l2 r2) (LensE l1 r1) = LensE l3 r3
  where l3 = assoc' . bimap id l2  . l1
        r3 = r1 . bimap id r2 . assoc
\end{haskell}
The left mapping in the new lens is given by the following composite:
\[ s \xrightarrow{l_1} (c, a)   \xrightarrow{(id, l_2)} (c, (c', a'))  \xrightarrow{assoc'} ((c, c'), a')\]
and the right mapping is given by:
\[ ((c, c'), b') \xrightarrow{assoc}  (c, (c', b')) \xrightarrow{(id, r_2)} (c, b) \xrightarrow{r_1} t \]

We have used the associativity and functoriality of the product:
\begin{haskell}
assoc :: ((c, c'), b') -> (c, (c', b'))
assoc ((c, c'), b') = (c, (c', b'))

assoc' :: (c, (c', a')) -> ((c, c'), a')
assoc' (c, (c', a')) = ((c, c'), a')

instance Bifunctor (,) where
  bimap f g (a, b) = (f a, g b)
\end{haskell}

As an example, let's compose two product lenses:
\begin{haskell}
l3 :: LensE (c, (c', a')) (c, (c', b')) a' b'
l3 = compLens prodLens prodLens
\end{haskell}
and apply it to a nested product:
\begin{haskell}
x :: (String, (Bool, Int))
x = ("Outer", (True, 42))
\end{haskell}
Our composite lens lets us not only retrieve the innermost component:
\begin{haskell}
toGet l3 x
> 42
\end{haskell}
but also replace it with a value of a different type (here, \hask{Char}):
\begin{haskell}
toSet l3 x 'z'
> ("Outer",(True,'z'))
\end{haskell}

\subsection{Category of lenses}

Since lenses can be composed, you might be wondering if there is a category in which lenses are hom-sets. 

Indeed, there is a category $\mathbf{Lens}$ whose objects are pairs of objects in $\mathcal{C}$, and arrows from $\langle s, t\rangle$ to $ \langle a, b \rangle$ are elements of  $\mathcal{L} \langle s, t\rangle \langle a, b \rangle$.

The formula for the composition of existential lenses is too complicated to be useful in practice. In the next chapter we'll see an alternative representation of lenses using Tambara modules, in which composition is just a composition of functions.

\section{Lenses and Fibrations}

There is an alternative view of lenses using the language of fiber bundles. A projection $p$ that defines a fibration can be seen as ``decomposing'' the bundle $E$ into fibers. 

In this view, $p$ plays the role of \hask{get}:
\[ p \colon E \to B \]
The base $B$ represents the type of the focus and $E$ represents the type of the composite from which that focus can be extracted.

The other part of the lens, \hask{set}, is a mapping: 
\[ q \colon E \times B \to E \]
Let's see how we can interpret it using fibrations.
\subsection{Transport law}

We interpret $q$ as ``transporting'' an element of the bundle $E$ to a new fiber. The new fiber is specified by an element of $B$.

This property of the transport is expressed by the get/set lens law, or the \emph{transport} law, that says that ``you get what you set'':
\begin{haskell}
get (set s a) = a
\end{haskell}
We say that $q(s, a)$ transports $s$ to a new fiber over $a$:

\[
\begin{tikzpicture}

\def\yb{0}; % base
\def\yfb{0.6}; % fiber bottom
\def\yfs{1.1}; % s
\def\yfss{1.6}; % s'
\def\yft{2.2}; % fiber top

\def\dx{0.9};

\def\xbl{0};
\def\xbm{\xbl + \dx};
\def\xbmr{\xbl + 2*\dx};
\def\xbr{\xbl + 4*\dx};


\filldraw[fill=orange!30, draw=white] (\xbl, \yfb) rectangle (\xbr, \yft);

\draw (\xbl, \yb) -- (\xbr, \yb);

\draw[dashed] (\xbm, \yfb) -- (\xbm, \yft); %fiber
\draw[dashed] (\xbmr, \yfb) -- (\xbmr, \yft); %fiber

\filldraw[black] (\xbm, \yfs) circle (1 pt);
\node[left] at (\xbm, \yfs) {$s$};
\draw[blue] (\xbm, \yfs) edge[->, bend left] (\xbmr, \yfss);
\filldraw[black] (\xbmr, \yfss) circle (1 pt);
\node[right] at (\xbmr, \yfss) {$q(s, a)$};

\filldraw[black] (\xbmr, \yb) circle (1 pt);
\node[below] at (\xbmr, \yb) {$a$};

\node[above] at (\xbmr, \yft) {$p^{-1} a$};
\node[right] at (\xbr, \yb) {$B$};
\node[right] at (\xbr, \yft) {$E$};

\end{tikzpicture}
\]

We can rewrite this law in terms of $p$ and $q$:
\[ p \circ q = \pi_2 \]
where $\pi_2$ is the second projection from the product.

Equivalently, we can represent it as a commuting diagram:
\[
 \begin{tikzcd}
 E \times B
 \arrow[dd, "\varepsilon \times id"']
 \arrow[rd, "q"]
 \\
 & E
 \arrow[dl, "p"]
 \\
 B
  \end{tikzcd}
\]
Here, instead of using the projection $\pi_2$, I used a comonoidal counit $\varepsilon$:
\[ \varepsilon \colon E \to 1 \]
followed by the unit law for the product. Using a comonoid makes it easier to generalize this construction to a tensor product in a monoidal category. 

\subsection{Identity law}
Here's the set/get law or the \emph{identity} law. It says that ``nothing changes if you set what you get'':
\begin{haskell}
set s (get  s) = s
\end{haskell}
We can write it in terms of a comonoidal comultiplication:
\[ \delta \colon E \to E \times E \]
The set/get law requires the following composite to be an identity:
\[ E \xrightarrow{\delta} E \times E \xrightarrow{id \times p} E \times B \xrightarrow{q} E \]
Here's the illustration of this law in a bundle:
\[
\begin{tikzpicture}

\def\yb{0}; % base
\def\yfb{0.6}; % fiber bottom
\def\yfs{1.1}; % s
\def\yfss{1.6}; % s'
\def\yft{2.8}; % fiber top

\def\dx{0.9};

\def\xbl{0};
\def\xbm{\xbl + \dx};
\def\xbmr{\xbl + 2*\dx};
\def\xbr{\xbl + 4*\dx};


\filldraw[fill=orange!30, draw=white] (\xbl, \yfb) rectangle (\xbr, \yft);

\draw (\xbl, \yb) -- (\xbr, \yb);

\draw[dashed] (\xbmr, \yfb) -- (\xbmr, \yft); %fiber

\node at (\xbmr, \yfss) (s) {};
\draw[->,shorten <=6pt,shorten >=6pt, blue](s.west)arc(360:0:0.7);
\filldraw[black] (\xbmr, \yfss) circle (1 pt);
\node[left] at (\xbmr, \yfss) {$s = $};
\node[right] at (\xbmr, \yfss) {$q(s, a)$};

\filldraw[black] (\xbmr, \yb) circle (1 pt);
\node[below] at (\xbmr, \yb) {$a$};

\node[above] at (\xbmr, \yft) {$p^{-1} a$};
\node[right] at (\xbr, \yb) {$B$};
\node[right] at (\xbr, \yft) {$E$};

\end{tikzpicture}
\]

\subsection{Composition law}

Finally, here's the set/set law, or the \emph{composition} law. It says that ``the last set wins'':
\begin{haskell}
set (set s a) a' = set s a'
\end{haskell}
and the corresponding commuting diagram:
\[
 \begin{tikzcd}
 E \times B \times B
 \arrow[d, "id \times \varepsilon \times id"']
 \arrow[rd, "q \times id"]
 \\
 E \times B
 \arrow[d, "q"']
 & E \times B
 \arrow[dl, "q "]
 \\
 E
  \end{tikzcd}
\]
Again, to get rid of the middle $B$, I used the counit rather than a projection from the product.

This is what the set/set law looks like in a bundle:
\[
\begin{tikzpicture}

\def\yb{0}; % base
\def\yfb{0.6}; % fiber bottom
\def\yfs{1.3}; % s'
\def\yfss{2.1}; % s''
\def\yft{2.8}; % fiber top

\def\dx{1};

\def\xbl{0};
\def\xbm{\xbl + \dx};
\def\xbmr{\xbl + 2.5*\dx};
\def\xbmrr{\xbl + 4*\dx};
\def\xbr{\xbl + 7.2*\dx};


\filldraw[fill=orange!30, draw=white] (\xbl, \yfb) rectangle (\xbr, \yft);

\draw (\xbl, \yb) -- (\xbr, \yb);

\draw[dashed] (\xbm, \yfb) -- (\xbm, \yft); %fiber
\draw[dashed] (\xbmr, \yfb) -- (\xbmr, \yft); %fiber
\draw[dashed] (\xbmrr, \yfb) -- (\xbmrr, \yft); %fiber

\filldraw[black] (\xbm, \yfss) circle (1 pt);
\node[left] at (\xbm, \yfss) {$s$};

\draw[red] (\xbm, \yfss)  edge[->, bend left]  (\xbmr, \yfs);

\filldraw[black] (\xbmr, \yfs) circle (1 pt);
\node[right] at (\xbmr, \yfs) {$q(s, a)$};
\node[left] at (\xbmr, \yfs) {$s' =$};

\draw[blue] (\xbmr, \yfs) edge[->, bend left] (\xbmrr, \yfss);

\filldraw[black] (\xbmrr, \yfss) circle (1 pt);
\node[right] at (\xbmrr, \yfss) {$q(a', s') = q(a', s)$};

\draw (\xbm, \yfss) edge[->, bend left] (\xbmrr, \yfss);


\filldraw[black] (\xbmr, \yb) circle (1 pt);
\node[below] at (\xbmr, \yb) {$a$};

\filldraw[black] (\xbmrr, \yb) circle (1 pt);
\node[below] at (\xbmrr, \yb) {$a'$};

\node[above] at (\xbmr, \yft) {$p^{-1} a$};
\node[above] at (\xbmrr, \yft) {$p^{-1} a'$};
\node[right] at (\xbr, \yb) {$B$};
\node[right] at (\xbr, \yft) {$E$};

\end{tikzpicture}
\]

\subsection{Type-changing lens}

A type-changing lens generalizes transport to act between bundles. We have to define a whole family of bundles. We start with a category $\cat A$ whose objects define the types that we will use for the foci of our lens. 

We construct the set $B$ as the combined set of all elements of all focus types. $B$ is fibrated over $\cat A$---the projection $\pi$ sending an element of $B$ to its corresponding type. You may think of $B$ as the set of objects of the coslice category $1/ \cat A$.

The bundle of bundles $E$ is a set that's fibered over $B$ with the projection $p$. Since $B$ itself is fibered over $\cat A$, $E$ is transitively fibered over $\cat A$, with the composite projection $\pi \circ p$. It's this coarser fibration that splits $E$ into a family of bundles. Each of these bundles corresponds to a different type of the composite for a given focus type. A type-changing lens will move between these bundles. 

\[
\begin{tikzpicture}
\def\xl{-3};
\def\xr{0};
\def\yb{0};
\def\yt{2};

\def\dy{0.4};
\def\dx{0.5};

\def\a{(\xl, \yb)};
\def\b{(\xr, \yb)};
\def\c{(\xl, \yt)};
\def\d {(\xr, \yt)};

% _a second plane
\def\aa{(\xl + \dx, \yb + \dy)};
\def\ba{(\xr + \dx, \yb + \dy)};
\def\ca{(\xl + \dx, \yt + \dy)};
\def\da{(\xr + \dx, \yt + \dy)};

% _b third plane
\def\ab{(\xl + 2*\dx, \yb + 2*\dy)};
\def\bb{(\xr + 2*\dx, \yb + 2*\dy)};
\def\cb{(\xl + 2*\dx, \yt + 2*\dy)};
\def\db{(\xr + 2*\dx, \yt + 2*\dy)};

% shifted walls
\def\yshift{-1.5};
\def\xshift{1.5};

% E
\draw \a rectangle \d;
\draw[draw=black!40!green] \aa rectangle \da;
\draw \ab rectangle \db;

\draw \a -- \ab;
\draw \b -- \bb;
\draw \d -- \db;
\draw \c -- \cb;

\node[above] at \cb {$E$};

% B
% rebase yb (bottom)
\def\yb{\yshift}
% rebase xr (right wall)
\def\xr{0};

\draw \a -- \b;
\draw \ab -- \bb;
\draw[red] \aa -- \ba;
% diagonal
\draw \a -- \ab;
\draw \b -- \bb;
\draw \d -- \db;
\draw \c -- \cb;
\node[above] at \ab {$B$};


% A
% rebase yb (bottom)
\def\yb{\yshift}
% rebase xr (right wall)
\def\xr{\xshift};

\draw \b -- \bb;
\node[right] at \bb {$\cat A$};
\filldraw[black] \ba circle (1 pt);

%projections

\draw[red, shorten <=0.2cm, shorten >=0.2cm, ->] (0 + \dx, \yshift + \dy) -- node[above]{$\pi$} (\xshift +\dx, \yshift + \dy);

\draw[draw=black!40!green, shorten >=0.1cm, ->] (0 - \dx, 0 + 3 * \dy) -- node[below right]{$p$} (0 - \dx, \yshift + \dy);

\node[right] at (0 - \dx, 0 + 3 * \dy) {$s$};
\filldraw[black] (0 - \dx, 0 + 3 * \dy) circle (1 pt);


\end{tikzpicture}
\]

The projection $p$ takes an element $s \in E$ and produces an element $b \in B$ whose type is given by $\pi b$. This is the generalization of \hask{get}. 

The transport $q$, which corresponds to \hask{set}, takes an element $s \in E$ and an element $b \in B$ and produces a new element $t \in E$. The important observation is that $s$ and $t$ may belong to different sub-bundles of $E$.


The transport satisfies the following laws:

The get/set law (transport):

\[ p (q (b, s)) = b \]

The set/get law (identity):

\[ q ( p (s), s) = s \]

The set/set law (composition):

\[ q (c, q (b, s)) = q (c, s) \]

\section{Important Formulas}
This is a handy (co-)end calculus cheat-sheet.
\begin{itemize}
\item Continuity of the hom-functor:
\[\cat D\left(d, \int_a P\langle a, a \rangle \right) \cong \int_a \cat D \left(d, P\langle a, a \rangle \right) \]
\item Co-continuity of the hom-functor:
\[\cat D\left( \int^a P\langle a, a \rangle , d \right) \cong \int_a \cat D \left( P\langle a, a \rangle, d \right) \]
\item Ninja Yoneda:
\[ \int_{x} \mathbf{Set} (\mathcal{C}(a, x), F x) \cong F a \]
\item Ninja co-Yoneda:
\[ \int^{x} \mathcal{C}(x, a) \times F x \cong F a \]
\item Ninja Yoneda for contravariant functors (presheaves):
\[ \int_{x} \mathbf{Set} (\mathcal{C}(x, a), G x) \cong G a \]
\item Ninja co-Yoneda for contravariant functors:
\[ \int^{x} \mathcal{C}(a, x) \times G x \cong G a \]
\item Day convolution:
\[ (F \star G) x = \int^{a, b} \cat C (a \otimes b, x) \times F a \times G b \]

\end{itemize}


\end{document}